<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-MachineLearningAndDataMining/决策树" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/09/MachineLearningAndDataMining/决策树/" class="article-date">
  <time datetime="2018-08-09T10:41:51.000Z" itemprop="datePublished">2018-08-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/数据挖掘/">数据挖掘</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/09/MachineLearningAndDataMining/决策树/">决策树分类代码实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p>决策树算法是一种逼近离散函数值的方法。它是一种典型的分类方法，首先对数据进行处理，利用归纳算法生成可读的规则和决策树，然后使用决策对新数据进行分析。本质上决策树是通过一系列规则对数据进行分类的过程。</p>
<h1 id="1-属性选择度量"><a href="#1-属性选择度量" class="headerlink" title="1 属性选择度量"></a>1 属性选择度量</h1><p>属性选择度量是一种选择分类准则，把给定类标记的训练元祖的数据分区D“最好地”划分成单独类的启发式方法。</p>
<ul>
<li>信息增益  ID3使用信息增益作为属性选择度量</li>
<li>增益率 ID3后继C4.5使用它作为信息增益的扩充，试图克服一种偏倚</li>
<li>基尼指数 在CART中使用，基尼指数考虑每个属性的二元划分</li>
</ul>
<p>本文将使用信息增益作为属性的选择度量，下面是计算序列的信息熵的代码，参数attr_list代表的是该属性列表。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *;</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict,namedtuple</span><br><span class="line">filename = <span class="string">r'C:\Users\14259\Desktop\24周\electronics.csv'</span>;</span><br><span class="line">feat_names = [<span class="string">'RID'</span>,<span class="string">'age'</span>,<span class="string">'income'</span>,<span class="string">'student'</span>,<span class="string">'credit_rating'</span>];</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(filename)</span>:</span></span><br><span class="line">    csv_reader = csv.reader(open(filename,<span class="string">'r'</span>));</span><br><span class="line">    dataset = list(csv_reader)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集中属性和labels切分开</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_lables</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    dataattrs = list(zip(*dataset))</span><br><span class="line">    labels = dataattrs[<span class="number">-1</span>];</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">        <span class="keyword">del</span> item[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> dataset,labels</span><br><span class="line"></span><br><span class="line">dataset = load_data(filename);</span><br><span class="line">print(<span class="string">"data size is %d lines"</span> % len(dataset))</span><br><span class="line">dataset,labels = split_lables(dataset)</span><br><span class="line"><span class="comment"># print(dataset,labels)</span></span><br><span class="line">```    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># 计算信息熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shannon_entropy</span><span class="params">(attr_list)</span>:</span></span><br><span class="line">    attrs = set(attr_list)   <span class="comment"># 获取所有的属性值</span></span><br><span class="line">    attr_nums = &#123;key:attr_list.count(key) <span class="keyword">for</span> key <span class="keyword">in</span> attrs &#125;  <span class="comment"># 得到属性对应的数目</span></span><br><span class="line">    attr_probs = [v/len(attr_list) <span class="keyword">for</span> k,v <span class="keyword">in</span> attr_nums.items()]   <span class="comment"># 得到属性可能性列表</span></span><br><span class="line">    entropy = sum([-p*log2(p) <span class="keyword">for</span> p <span class="keyword">in</span> attr_probs]);   <span class="comment"># 计算信息熵</span></span><br><span class="line">    <span class="keyword">return</span> entropy</span><br><span class="line"></span><br><span class="line"><span class="comment"># attr_list = ["youth","youth","middle_aged","senior","senior","senior","middle_aged","youth","youth","senior","youth","middle_aged","middle_aged","senior"];</span></span><br><span class="line"><span class="comment"># attr_list = ["no",'no','yes','yes','yes','no','yes','no','yes','yes','yes','yes','yes','no'];</span></span><br><span class="line"><span class="comment"># get_shannon_entropy(attr_list)</span></span><br></pre></td></tr></table></figure>
<h2 id="1-1-使用信息增益选择属性"><a href="#1-1-使用信息增益选择属性" class="headerlink" title="1.1 使用信息增益选择属性"></a>1.1 使用信息增益选择属性</h2><p>按照步骤，计算对应数据集的属性的信息增益，选择最合适的属性作为分类属性。首先需要计算该属性划分数据集之后得到的对应的子数据集和子类型列表，之后在进行相应的信息熵的计算。</p>
<ul>
<li>划分数据集</li>
<li>计算信息增益，选择最佳属性</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span><span class="params">(dataset, labels,feat_index)</span>:</span></span><br><span class="line">    <span class="string">""" 根据某个特征划分数据集</span></span><br><span class="line"><span class="string">    dataset：原始数据集，不包含标签</span></span><br><span class="line"><span class="string">    labels: 对应的标签</span></span><br><span class="line"><span class="string">    feat_index：特征在特征向量中的索引</span></span><br><span class="line"><span class="string">    return  ：返回以feat_index作为分类属性的时候，该属性对应的取值的子数据集和对应的类型。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dataset = copy.deepcopy(dataset)   <span class="comment"># 避免删除元素造成影响</span></span><br><span class="line">    <span class="comment"># 1、将每一列元素放在一个元组中，使用zip函数</span></span><br><span class="line">    dataset_zip =list( zip(*dataset))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#2、获取该特征列</span></span><br><span class="line">    feat_col = dataset_zip[feat_index];</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#3、根据该列特征的所有取值，构建一个字典，键为属性的取值，值为对应的数据集。</span></span><br><span class="line">    splited_dict = &#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> set(feat_col):</span><br><span class="line">        splited_dict[item] = [[],[]];</span><br><span class="line">        </span><br><span class="line"><span class="comment">#     print(splited_dict)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feat_col)):    <span class="comment"># 该特征列不能存在缺失，否则会有问题</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> splited_dict.keys():</span><br><span class="line">            <span class="keyword">if</span> feat_col[i] == key:</span><br><span class="line">                <span class="keyword">del</span> dataset[i][feat_index]      <span class="comment"># 删除该特征列的信息，表示该特征列已经用过了。</span></span><br><span class="line">                splited_dict[key][<span class="number">0</span>].append(dataset[i])</span><br><span class="line">                splited_dict[key][<span class="number">1</span>].append(labels[i])</span><br><span class="line">    <span class="keyword">return</span> splited_dict</span><br><span class="line">        </span><br><span class="line">split_dataset(dataset,labels,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据信息增益选择属性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_best_split_attr</span><span class="params">(dataset,labels)</span>:</span></span><br><span class="line">    <span class="string">"""dataset是数据集。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"><span class="comment">#     # 1、从带标签的数据集中取出标签列</span></span><br><span class="line"><span class="comment">#     labels = list(zip(*dataset))[-1]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、计算labels中分类所需要的期望信息</span></span><br><span class="line">    entropy_all = get_shannon_entropy(labels)</span><br><span class="line"><span class="comment">#     print(entropy_all)</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 3、计算每个属性的期望信息需求</span></span><br><span class="line">    entropys = &#123;&#125;;   <span class="comment"># 存储对应的entropys</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(dataset[<span class="number">0</span>])):    <span class="comment"># 注意这里是使用1开始的，因为如果从0开始，那么第一个序号属性会使最好的分类属性，</span></span><br><span class="line">            <span class="comment"># 因为它将每一个数据都划分成一个类，这显然是没有意义的，这也是偏倚出现的原因，可以使用增益率作为属性选择计算方法来避免。</span></span><br><span class="line">        <span class="comment"># 划分数据集，返回的是一个字典</span></span><br><span class="line">        split_data = split_dataset(dataset,labels,i)</span><br><span class="line">        entropys[i] = [];</span><br><span class="line">        <span class="keyword">for</span> k,v <span class="keyword">in</span> split_data.items():</span><br><span class="line">            <span class="comment"># split_data字典中，键是属性值，值=[子数据集，子类型列表]</span></span><br><span class="line">            k_rate = len(v[<span class="number">0</span>])/len(labels)    <span class="comment"># 该属性对应的数据集的个数占数据集总个数的比例</span></span><br><span class="line">            entropy = get_shannon_entropy(v[<span class="number">1</span>])   <span class="comment"># 计算该属性对应的数据标签的信息熵。</span></span><br><span class="line">            temp = k_rate*entropy;</span><br><span class="line">            entropys[i].append(temp)</span><br><span class="line">        entropys[i] = sum(entropys[i])    <span class="comment"># 计算属性i进行划分的时候的期望信息</span></span><br><span class="line"><span class="comment">#     print(entropys)</span></span><br><span class="line">    <span class="keyword">return</span> min(entropys,key=entropys.get)</span><br><span class="line">    </span><br><span class="line">choose_best_split_attr(dataset,labels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 比如以第三个属性作为特征值进行手动的计算entropy</span></span><br><span class="line">result = (<span class="number">7</span>/<span class="number">14</span>)*(-(<span class="number">4</span>/<span class="number">7</span>)*log2(<span class="number">4</span>/<span class="number">7</span>)-(<span class="number">3</span>/<span class="number">7</span>)*log2(<span class="number">3</span>/<span class="number">7</span>))+(<span class="number">7</span>/<span class="number">14</span>)*(-(<span class="number">6</span>/<span class="number">7</span>)*log2(<span class="number">6</span>/<span class="number">7</span>)-(<span class="number">1</span>/<span class="number">7</span>)*log2(<span class="number">1</span>/<span class="number">7</span>))</span><br><span class="line">result     <span class="comment"># 与上面计算的结果一致，可以看出算法正确</span></span><br></pre></td></tr></table></figure>
<h1 id="2-树分裂"><a href="#2-树分裂" class="headerlink" title="2 树分裂"></a>2 树分裂</h1><p>有了选取最佳分裂属性的算法，接着就开始使用选择的属性来将树进一步的分裂。所谓树的分裂只不过是根据选择的属性将数据集划分，然后在总划分出来的数据集中再次调用选取属性的方法选择子数据集的最佳属性，最好的实现方式就是递归了。<br>python中使用什么数据结构表示决策树？可以使用字典很方便的表示决策树的嵌套，一个树的根节点便是属性，属性对应的值又是一个新的字典，其中key为属性的可能值，value为子树。</p>
<h2 id="2-1-得到占据大多数的类型"><a href="#2-1-得到占据大多数的类型" class="headerlink" title="2.1 得到占据大多数的类型"></a>2.1 得到占据大多数的类型</h2><p>当所有属性都使用完的时候还没有将数据完全分开，此时就返回所占比重较大的那个分类。比如使用完最后一个属性，得到的labels列表为[‘yes’,’yes’,’no’]那么返回的就是yes类型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_majority</span><span class="params">(labels)</span>:</span></span><br><span class="line">    label_nums = defaultdict(<span class="keyword">lambda</span>:<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">        label_nums[label] += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> max(label_nums, key=label_nums.get)</span><br><span class="line"></span><br><span class="line"><span class="comment"># labels = ['yes','yes','no'];</span></span><br><span class="line"><span class="comment"># print(get_majority(labels));</span></span><br></pre></td></tr></table></figure>
<h2 id="2-2-创建树"><a href="#2-2-创建树" class="headerlink" title="2.2 创建树"></a>2.2 创建树</h2><p>树分裂终止的两个条件是：</p>
<ul>
<li>遍历完所有的属性。在进行树分裂的时候，我们数据集中数据向量的属性是不断缩短的，当缩短到1的时候（数据向量中包括labels，所以这里为1.否则为0），说明数据集中的属性已被全部使用完毕，便不能再分裂下去了，此时我们选取最终子数据集中的众数作为最终的分类结果放在叶子节点上。</li>
<li>新划分的数据集中只有一个属性。所该节点下面的子数据集中labels是一致的，那么就不用在进行分类了。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(dataset, labels, feat_names)</span>:</span></span><br><span class="line">    <span class="string">"""dataset是含有标签的数据集，labels是对应的标签，feat_names是数据集中数据相应的特征属性</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">global</span> Tree;</span><br><span class="line">    <span class="keyword">if</span> (len(set(labels)) == <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 如果数据集中只有一个类型，就可以停止分裂</span></span><br><span class="line">        <span class="keyword">return</span> labels[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(feat_names) == <span class="number">1</span>:  <span class="comment"># 因为没有考虑第一个属性RID</span></span><br><span class="line">        <span class="comment"># 如果属性已经用完了，那么返回比例最多的类型。</span></span><br><span class="line">        <span class="keyword">return</span> get_majority(labels)</span><br><span class="line"></span><br><span class="line">    tree = &#123;&#125;;</span><br><span class="line">    best_feature_index = choose_best_split_attr(dataset, labels);  <span class="comment"># 获取最好的分类属性的index</span></span><br><span class="line">    feature = feat_names[best_feature_index];  <span class="comment"># 获取属性index对应的属性名</span></span><br><span class="line">    tree[feature] = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    sub_feat_names = feat_names[:];</span><br><span class="line">    <span class="comment">#     print(sub_feat_names[best_feature_index])</span></span><br><span class="line">    sub_feat_names.pop(best_feature_index);</span><br><span class="line"></span><br><span class="line">    splited_dict = split_dataset(dataset, labels, best_feature_index);  <span class="comment"># 根据该属性分类，得到分类之后的数据集</span></span><br><span class="line">    <span class="keyword">for</span> feat_col, (sub_dataset, sub_labels) <span class="keyword">in</span> splited_dict.items():</span><br><span class="line">        tree[feature][feat_col] = create_tree(sub_dataset, sub_labels, sub_feat_names)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tree;</span><br><span class="line"></span><br><span class="line">create_tree(dataset,labels,feat_names)</span><br></pre></td></tr></table></figure>
<pre><code>{&apos;age&apos;: {&apos;middle_aged&apos;: &apos;yes&apos;,
  &apos;senior&apos;: {&apos;credit_rating&apos;: {&apos;excellent&apos;: &apos;no&apos;, &apos;fair&apos;: &apos;yes&apos;}},
  &apos;youth&apos;: {&apos;student&apos;: {&apos;no&apos;: &apos;no&apos;, &apos;yes&apos;: &apos;yes&apos;}}}}
</code></pre><h1 id="3-合并所有代码"><a href="#3-合并所有代码" class="headerlink" title="3 合并所有代码"></a>3 合并所有代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *;</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"></span><br><span class="line">filename = <span class="string">r'C:\Users\14259\Desktop\24周\electronics.csv'</span>;</span><br><span class="line">feat_names = [<span class="string">'RID'</span>, <span class="string">'age'</span>, <span class="string">'income'</span>, <span class="string">'student'</span>, <span class="string">'credit_rating'</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(filename)</span>:</span></span><br><span class="line">    csv_reader = csv.reader(open(filename, <span class="string">'r'</span>));</span><br><span class="line">    dataset = list(csv_reader)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据集中属性和labels切分开</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_lables</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    dataattrs = list(zip(*dataset))</span><br><span class="line">    labels = dataattrs[<span class="number">-1</span>];</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> dataset:</span><br><span class="line">        <span class="keyword">del</span> item[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> dataset, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算信息熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_shannon_entropy</span><span class="params">(attr_list)</span>:</span></span><br><span class="line">    attrs = set(attr_list)  <span class="comment"># 获取所有的属性值</span></span><br><span class="line">    attr_nums = &#123;key: attr_list.count(key) <span class="keyword">for</span> key <span class="keyword">in</span> attrs&#125;  <span class="comment"># 得到属性对应的数目</span></span><br><span class="line">    attr_probs = [v / len(attr_list) <span class="keyword">for</span> k, v <span class="keyword">in</span> attr_nums.items()]  <span class="comment"># 得到属性可能性列表</span></span><br><span class="line">    entropy = sum([-p * log2(p) <span class="keyword">for</span> p <span class="keyword">in</span> attr_probs]);  <span class="comment"># 计算信息熵</span></span><br><span class="line">    <span class="keyword">return</span> entropy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">split_dataset</span><span class="params">(dataset, labels, feat_index)</span>:</span></span><br><span class="line">    <span class="string">""" 根据某个特征划分数据集</span></span><br><span class="line"><span class="string">    dataset：原始数据集，不包含标签</span></span><br><span class="line"><span class="string">    labels: 对应的标签</span></span><br><span class="line"><span class="string">    feat_index：特征在特征向量中的索引</span></span><br><span class="line"><span class="string">    return  ：返回以feat_index作为分类属性的时候，该属性对应的取值的子数据集和对应的类型。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dataset = copy.deepcopy(dataset)  <span class="comment"># 避免删除元素造成影响</span></span><br><span class="line">    <span class="comment"># 1、将每一列元素放在一个元组中，使用zip函数</span></span><br><span class="line">    dataset_zip = list(zip(*dataset))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、获取该特征列</span></span><br><span class="line">    feat_col = dataset_zip[feat_index];</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3、根据该列特征的所有取值，构建一个字典，键为属性的取值，值为对应的数据集。</span></span><br><span class="line">    splited_dict = &#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> set(feat_col):</span><br><span class="line">        splited_dict[item] = [[], []];</span><br><span class="line"></span><br><span class="line">    <span class="comment">#     print(splited_dict)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(feat_col)):  <span class="comment"># 该特征列不能存在缺失，否则会有问题</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> splited_dict.keys():</span><br><span class="line">            <span class="keyword">if</span> feat_col[i] == key:</span><br><span class="line">                <span class="keyword">del</span> dataset[i][feat_index]  <span class="comment"># 删除该特征列的信息，表示该特征列已经用过了。</span></span><br><span class="line">                splited_dict[key][<span class="number">0</span>].append(dataset[i])</span><br><span class="line">                splited_dict[key][<span class="number">1</span>].append(labels[i])</span><br><span class="line">    <span class="keyword">return</span> splited_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据信息增益选择属性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_best_split_attr</span><span class="params">(dataset, labels)</span>:</span></span><br><span class="line">    <span class="string">"""dataset是数据集。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#     # 1、从带标签的数据集中取出标签列</span></span><br><span class="line">    <span class="comment">#     labels = list(zip(*dataset))[-1]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2、计算labels中分类所需要的期望信息</span></span><br><span class="line">    entropy_all = get_shannon_entropy(labels)</span><br><span class="line">    <span class="comment">#     print(entropy_all)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3、计算每个属性的期望信息需求</span></span><br><span class="line">    entropys = &#123;&#125;;  <span class="comment"># 存储对应的entropys</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(dataset[<span class="number">0</span>])):  <span class="comment"># 注意这里是使用1开始的，因为如果从0开始，那么第一个序号属性会使最好的分类属性，</span></span><br><span class="line">        <span class="comment"># 因为它将每一个数据都划分成一个类，这显然是没有意义的，这也是偏倚出现的原因，可以使用增益率作为属性选择计算方法来避免。</span></span><br><span class="line">        <span class="comment"># 划分数据集，返回的是一个字典</span></span><br><span class="line">        split_data = split_dataset(dataset, labels, i)</span><br><span class="line">        entropys[i] = [];</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> split_data.items():</span><br><span class="line">            <span class="comment"># split_data字典中，键是属性值，值=[子数据集，子类型列表]</span></span><br><span class="line">            k_rate = len(v[<span class="number">0</span>]) / len(labels)  <span class="comment"># 该属性对应的数据集的个数占数据集总个数的比例</span></span><br><span class="line">            entropy = get_shannon_entropy(v[<span class="number">1</span>])  <span class="comment"># 计算该属性对应的数据标签的信息熵。</span></span><br><span class="line">            temp = k_rate * entropy;</span><br><span class="line">            entropys[i].append(temp)</span><br><span class="line">        entropys[i] = sum(entropys[i])  <span class="comment"># 计算属性i进行划分的时候的期望信息</span></span><br><span class="line">    <span class="comment">#     print(entropys)</span></span><br><span class="line">    <span class="keyword">return</span> min(entropys, key=entropys.get)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_majority</span><span class="params">(labels)</span>:</span></span><br><span class="line">    label_nums = defaultdict(<span class="keyword">lambda</span>: <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">        label_nums[label] += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> max(label_nums, key=label_nums.get)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_tree</span><span class="params">(dataset, labels, feat_names)</span>:</span></span><br><span class="line">    <span class="string">"""dataset是含有标签的数据集，labels是对应的标签，feat_names是数据集中数据相应的特征属性</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">global</span> Tree;</span><br><span class="line">    <span class="keyword">if</span> (len(set(labels)) == <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 如果数据集中只有一个类型，就可以停止分裂</span></span><br><span class="line">        <span class="keyword">return</span> labels[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(feat_names) == <span class="number">1</span>:  <span class="comment"># 因为没有考虑第一个属性RID</span></span><br><span class="line">        <span class="comment"># 如果属性已经用完了，那么返回比例最多的类型。</span></span><br><span class="line">        <span class="keyword">return</span> get_majority(labels)</span><br><span class="line"></span><br><span class="line">    tree = &#123;&#125;;</span><br><span class="line">    best_feature_index = choose_best_split_attr(dataset, labels);  <span class="comment"># 获取最好的分类属性的index</span></span><br><span class="line">    feature = feat_names[best_feature_index];  <span class="comment"># 获取属性index对应的属性名</span></span><br><span class="line">    tree[feature] = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    sub_feat_names = feat_names[:];</span><br><span class="line">    <span class="comment">#     print(sub_feat_names[best_feature_index])</span></span><br><span class="line">    sub_feat_names.pop(best_feature_index);</span><br><span class="line"></span><br><span class="line">    splited_dict = split_dataset(dataset, labels, best_feature_index);  <span class="comment"># 根据该属性分类，得到分类之后的数据集</span></span><br><span class="line">    <span class="keyword">for</span> feat_col, (sub_dataset, sub_labels) <span class="keyword">in</span> splited_dict.items():</span><br><span class="line">        tree[feature][feat_col] = create_tree(sub_dataset, sub_labels, sub_feat_names)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tree;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    dataset = load_data(filename);</span><br><span class="line">    print(<span class="string">"data size is %d lines"</span> % len(dataset))</span><br><span class="line">    dataset, labels = split_lables(dataset)</span><br><span class="line">    tree = create_tree(dataset, labels, feat_names)</span><br><span class="line">    print(<span class="string">"生成的决策树如下:"</span>)</span><br><span class="line">    print(tree)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<pre><code>data size is 14 lines
生成的决策树如下:
{&apos;age&apos;: {&apos;senior&apos;: {&apos;credit_rating&apos;: {&apos;excellent&apos;: &apos;no&apos;, &apos;fair&apos;: &apos;yes&apos;}}, &apos;youth&apos;: {&apos;student&apos;: {&apos;yes&apos;: &apos;yes&apos;, &apos;no&apos;: &apos;no&apos;}}, &apos;middle_aged&apos;: &apos;yes&apos;}}
</code></pre><h1 id="4-可视化决策树"><a href="#4-可视化决策树" class="headerlink" title="4 可视化决策树"></a>4 可视化决策树</h1><p>通过嵌套字典表示决策树对人来说不好理解，可以借助可视化工具将该结构可视化。使用Graphviz来可视化树结构。因此，首先需要将字典表示的树生成 Graphviz Dot文件内容的函数，思想就是递归获取整棵树的所有节点和连接节点的边然后将这些节点和边生成Dot格式的字符串写入到文件中，然后进行图形的绘制。<br><strong>这一部分内容暂时没有做，需要安装Graphviz软件以及学习使用。</strong></p>
<h1 id="5-使用生成的决策树进行分类"><a href="#5-使用生成的决策树进行分类" class="headerlink" title="5 使用生成的决策树进行分类"></a>5 使用生成的决策树进行分类</h1><p>对未知数据进行预测，主要是根据树中的结点递归找到叶子结点即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(data_vect,feat_names,tree)</span>:</span></span><br><span class="line">    <span class="keyword">if</span>(type(tree) <span class="keyword">is</span> <span class="keyword">not</span> dict):</span><br><span class="line">        <span class="comment"># 说明找到了叶子结点</span></span><br><span class="line">        <span class="keyword">return</span> tree;  </span><br><span class="line">    </span><br><span class="line">    feature = list(tree.keys())[<span class="number">0</span>]   <span class="comment"># 获取树的最顶层的属性</span></span><br><span class="line">    value = data_vect[feat_names.index(feature)]  <span class="comment">#获取测试数据该属性对应的值</span></span><br><span class="line">    sub_tree = tree[feature][value]</span><br><span class="line">    <span class="keyword">return</span> classify(data_vect,feat_names,sub_tree)</span><br><span class="line"><span class="comment"># data_vect = [14,'senior','medium','no','fair'];</span></span><br><span class="line"><span class="comment"># label = classify(data_vect,feat_names,tree);</span></span><br><span class="line"><span class="comment"># print(label)</span></span><br></pre></td></tr></table></figure>
<pre><code>yes
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_accuracy</span><span class="params">(dataset,labels,feat_names,tree)</span>:</span></span><br><span class="line">    predict_labels = [];</span><br><span class="line">    <span class="keyword">for</span> data_vect <span class="keyword">in</span> dataset:</span><br><span class="line">        label = classify(data_vect,feat_names,tree)</span><br><span class="line">        predict_labels.append(label)</span><br><span class="line">    </span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    labels =list(zip(predict_labels,labels))</span><br><span class="line">    <span class="keyword">for</span> label <span class="keyword">in</span> labels:</span><br><span class="line">        <span class="keyword">if</span> label[<span class="number">0</span>] == label[<span class="number">1</span>]:</span><br><span class="line">            count += <span class="number">1</span>;</span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> count/len(dataset)</span><br><span class="line"></span><br><span class="line">dataset =[[<span class="string">'1'</span>, <span class="string">'youth'</span>, <span class="string">'high'</span>, <span class="string">'no'</span>, <span class="string">'fair'</span>], [<span class="string">'2'</span>, <span class="string">'youth'</span>, <span class="string">'high'</span>, <span class="string">'no'</span>, <span class="string">'excellent'</span>], [<span class="string">'3'</span>, <span class="string">'middle_aged'</span>, <span class="string">'high'</span>, <span class="string">'no'</span>, <span class="string">'fair'</span>], [<span class="string">'4'</span>, <span class="string">'senior'</span>, <span class="string">'medium'</span>, <span class="string">'no'</span>, <span class="string">'fair'</span>], [<span class="string">'5'</span>, <span class="string">'senior'</span>, <span class="string">'low'</span>, <span class="string">'yes'</span>, <span class="string">'fair'</span>], [<span class="string">'6'</span>, <span class="string">'senior'</span>, <span class="string">'low'</span>, <span class="string">'yes'</span>, <span class="string">'excellent'</span>]]</span><br><span class="line">labels = [<span class="string">'no'</span>, <span class="string">'no'</span>, <span class="string">'no'</span>, <span class="string">'no'</span>, <span class="string">'yes'</span>, <span class="string">'no'</span>, <span class="string">'yes'</span>]</span><br><span class="line">accuracy = predict_accuracy(dataset,labels,feat_names,tree)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"准确率是: %.4f"</span> % accuracy)</span><br></pre></td></tr></table></figure>
<pre><code>准确率是: 0.6667
</code></pre><h1 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h1><p>本文一步步实现了一个基本的决策树分类算法，里面还有较多不完善的地方。</p>
<ul>
<li>比如在属性选择方面，使用的是信息增益，可能存在偏倚问题。之后可以通过增益率作为属性选择度量。</li>
<li>如果测试数据中出现了训练数据中没有出现的某个属性的类别，那么会出现错误。</li>
<li>本文没有涉及到树剪枝等问题，可能是数据集比较简单，没有遇到该类问题。<br>写本文主要是为了熟悉决策树的一个分类的原理，从而可以更好的理解，之后在进行使用的时候可以使用目前比较完善的，比如scikit-learn</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/09/MachineLearningAndDataMining/决策树/" data-id="cjtinfpse005exw772j10dh64" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/决策树/">决策树</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分类/">分类</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-MachineLearningAndDataMining/朴素贝叶斯" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/07/MachineLearningAndDataMining/朴素贝叶斯/" class="article-date">
  <time datetime="2018-08-07T08:17:51.000Z" itemprop="datePublished">2018-08-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/数据挖掘/">数据挖掘</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/07/MachineLearningAndDataMining/朴素贝叶斯/">朴素贝叶斯分类代码实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>朴素贝叶斯分类的流程可以看下图。  </p>
<p><img src="/images/DataMiningTheory/BayesAndDecesionTree/Bayes_01" width="400px;" height="400px"></p>
<p>本文主要是通过代码一步步实现一个高斯朴素贝叶斯分类程序。</p>
<h1 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1 数据预处理"></a>1 数据预处理</h1><h2 id="1-1-读取和处理数据"><a href="#1-1-读取和处理数据" class="headerlink" title="1.1 读取和处理数据"></a>1.1 读取和处理数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">filename = <span class="string">r'C:\Users\14259\Desktop\23周\wine.csv'</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1、导入csv文件</span></span><br><span class="line">csv_file = csv.reader(open(<span class="string">r'C:\Users\14259\Desktop\23周\wine.csv'</span>,<span class="string">'r'</span>))</span><br><span class="line">print(csv_file)  <span class="comment"># 这里是一个csv.reader的对象</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> csv_file:</span><br><span class="line">    print(item)</span><br><span class="line">    <span class="comment"># 这里没有输出对应的item，因为数据较多。</span></span><br></pre></td></tr></table></figure>
<pre><code>&lt;_csv.reader object at 0x000001EF4B0DEA70&gt;
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将读取文件内容封装成方法，存到二维数组中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadCsvFile</span><span class="params">(filename)</span>:</span></span><br><span class="line">    csv_reader = csv.reader(open(filename,<span class="string">'r'</span>))</span><br><span class="line">    dataset = list(csv_reader)</span><br><span class="line"><span class="comment">#     print(dataset)</span></span><br><span class="line">    <span class="comment"># 将数据类型由字符串转换成浮点数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">        dataset[i] = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> dataset[i]]</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line">    </span><br><span class="line">dataset = loadCsvFile(filename)</span><br><span class="line">print(<span class="string">"loaded data file &#123;0&#125; with &#123;1&#125; lines"</span>.format (filename,len(dataset)))</span><br></pre></td></tr></table></figure>
<pre><code>输出：loaded data file C:\Users\14259\Desktop\23周\wine.csv with 178 lines
</code></pre><h2 id="1-2-将数据集进行划分"><a href="#1-2-将数据集进行划分" class="headerlink" title="1.2 将数据集进行划分"></a>1.2 将数据集进行划分</h2><p>将数据集随机分为包含67%的训练集和33%的测试集（这是在次数据集上测试算法的通常比率）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataset</span><span class="params">(dataset,splitRatio)</span>:</span></span><br><span class="line">    <span class="comment"># splitRation 是训练数据占得比例</span></span><br><span class="line">    data= copy.deepcopy(dataset)</span><br><span class="line">    length = len(dataset)</span><br><span class="line">    trainSize= math.floor(length*splitRatio)</span><br><span class="line">    trainData = []</span><br><span class="line">    <span class="keyword">while</span>(len(trainData)&lt;trainSize):</span><br><span class="line">        index = random.randint(<span class="number">0</span>,len(data)<span class="number">-1</span>)</span><br><span class="line">        trainData.append(data.pop(index))</span><br><span class="line">    testData = data</span><br><span class="line">    <span class="keyword">return</span> [trainData,testData]</span><br><span class="line"></span><br><span class="line">trainData,testData = splitDataset(dataset,<span class="number">0.67</span>)</span><br><span class="line"><span class="comment"># print(len(trainData),len(testData))</span></span><br><span class="line">print(<span class="string">"train data is %d lines and test data is %d lines"</span> % (len(trainData),len(testData)))</span><br><span class="line"><span class="comment"># print(trainData)</span></span><br></pre></td></tr></table></figure>
<pre><code>输出：train data is 119 lines and test data is 59 lines
</code></pre><h2 id="1-3-提取数据特征"><a href="#1-3-提取数据特征" class="headerlink" title="1.3 提取数据特征"></a>1.3 提取数据特征</h2><p>所收集的训练数据的特征，包含相对于每个类的每个属性的均值和标准差。像本数据集，共有3个类别，13个属性，然后我们需要每一个属性和类别组合的均值和标准差，也就是39个属性特征。  </p>
<p>需要完成以下几个任务</p>
<ul>
<li>按照类别进行划分，本数据集共含有三个类别，可以划分成对应的三组数据</li>
<li>计算均值、标准差</li>
<li>提取属性特征</li>
</ul>
<h3 id="1-3-1-类别划分"><a href="#1-3-1-类别划分" class="headerlink" title="1.3.1 类别划分"></a>1.3.1 类别划分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将类别作为键，对应类别的值等作为改建对应的值</span></span><br><span class="line"><span class="comment"># 1、按照类别进行数据分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">separateByClass</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    dataClass = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">        item = dataset[i]  </span><br><span class="line">        <span class="keyword">if</span>(item[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> dataClass.keys()):  <span class="comment"># 如果没有该键值</span></span><br><span class="line">            dataClass[item[<span class="number">0</span>]] = []</span><br><span class="line">        dataClass[item[<span class="number">0</span>]].append(item)</span><br><span class="line">    <span class="keyword">return</span> dataClass</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataClass = separateByClass(trainData)</span></span><br><span class="line"><span class="comment"># # print(dataClass)</span></span><br><span class="line"><span class="comment"># print("class 1 has %d lines, class 2 has %d lines, class 3 has %d lines" % (len(dataClass[1.0]), len(dataClass[2.0]), len(dataClass[3.0])))</span></span><br></pre></td></tr></table></figure>
<h3 id="1-3-2-计算均值和标准差"><a href="#1-3-2-计算均值和标准差" class="headerlink" title="1.3.2 计算均值和标准差"></a>1.3.2 计算均值和标准差</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numbers是要计算均值的数据列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sum(numbers) / float(len(numbers));</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stdev</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    avg = mean(numbers)</span><br><span class="line">    variance = sum([pow(x-avg,<span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> numbers])/(float(len(numbers)<span class="number">-1</span>))  <span class="comment"># 这里使用len(numbers)-1,可以参考百度百科【标准差】的说法</span></span><br><span class="line">    <span class="keyword">return</span> math.sqrt(variance)</span><br></pre></td></tr></table></figure>
<h3 id="1-3-3-提出属性特征"><a href="#1-3-3-提出属性特征" class="headerlink" title="1.3.3 提出属性特征"></a>1.3.3 提出属性特征</h3><p>接着就是针对每一个类别，计算每一个属性的均值和标准差。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用zip，可以将对应的属性整合到一个元祖中，然后在进行计算。</span></span><br><span class="line">test = [[<span class="number">1</span>,<span class="number">20</span>,<span class="number">0</span>],[<span class="number">2</span>,<span class="number">21</span>,<span class="number">0</span>],[<span class="number">3</span>,<span class="number">22</span>,<span class="number">1</span>]]</span><br><span class="line">print(*test)   <span class="comment"># 将列表拆分成单个元素进行传输</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将列表中对应的项组合起来，形成元组</span></span><br><span class="line">print(list(zip(*test)))</span><br></pre></td></tr></table></figure>
<pre><code>输出：[1, 20, 0] [2, 21, 0] [3, 22, 1]
[(1, 2, 3), (20, 21, 22), (0, 0, 1)]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">summrize</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    summaries = [(mean(attributes),stdev(attributes)) <span class="keyword">for</span> attributes <span class="keyword">in</span> zip(*dataset)]</span><br><span class="line">    <span class="keyword">del</span> summaries[<span class="number">0</span>]   <span class="comment"># 第一列表示的是类别列，不需要，可以删除</span></span><br><span class="line">    <span class="keyword">return</span> summaries</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以得到对应每个属性的均值和标准差</span></span><br><span class="line"><span class="comment"># dataset = [[2.0, 13.05, 3.86, 2.32, 22.5, 85.0, 1.65, 1.59, 0.61, 1.62, 4.8, 0.84, 2.01, 515.0], [2.0, 12.16, 1.61, 2.31, 22.8, 90.0, 1.78, 1.69, 0.43, 1.56, 2.45, 1.33, 2.26, 495.0], [2.0, 12.0, 1.51, 2.42, 22.0, 86.0, 1.45, 1.25, 0.5, 1.63, 3.6, 1.05, 2.65, 450.0], [2.0, 11.62, 1.99, 2.28, 18.0, 98.0, 3.02, 2.26, 0.17, 1.35, 3.25, 1.16, 2.96, 345.0]]</span></span><br><span class="line"><span class="comment"># summrize(dataset)</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始按照类别提取属性特征</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">summrizeByClass</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    seperateData = separateByClass(dataset)      <span class="comment"># 获取分类之后的数据</span></span><br><span class="line">    summaries = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> seperateData.items():</span><br><span class="line">        summaries[key] = summrize(value)</span><br><span class="line">    <span class="keyword">return</span> summaries</span><br><span class="line"></span><br><span class="line"><span class="comment"># # 得到每个类别的均值和标准差</span></span><br><span class="line"><span class="comment"># dataset = loadCsvFile(filename)</span></span><br><span class="line"><span class="comment"># summrizeByClass(dataset)</span></span><br><span class="line">summaries = summrizeByClass(trainData)</span><br><span class="line"><span class="comment"># print(summaries)</span></span><br></pre></td></tr></table></figure>
<h1 id="2-预测"><a href="#2-预测" class="headerlink" title="2 预测"></a>2 预测</h1><p>现在开始计算归属每个类的概率</p>
<ul>
<li>计算高斯概率密度函数</li>
<li>计算对应类的概率</li>
<li>单一预测</li>
<li>评估</li>
</ul>
<h2 id="2-1-计算高斯概率密度函数"><a href="#2-1-计算高斯概率密度函数" class="headerlink" title="2.1 计算高斯概率密度函数"></a>2.1 计算高斯概率密度函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateGauss</span><span class="params">(x,mean,stdev)</span>:</span></span><br><span class="line">    <span class="comment"># x表示对应的属性值，mean是该属性在某一类别下的均值，stdev是标准差</span></span><br><span class="line">    fenmu = math.exp(-math.pow((x-mean),<span class="number">2</span>)/(<span class="number">2</span>*math.pow(stdev,<span class="number">2</span>)))</span><br><span class="line">    fenzi = math.sqrt(<span class="number">2</span>*math.pi)*stdev</span><br><span class="line">    <span class="keyword">return</span> fenmu/fenzi</span><br><span class="line"><span class="comment"># 得到的是高斯分布函数的计算结果</span></span><br></pre></td></tr></table></figure>
<h2 id="2-2-计算所属类的概率"><a href="#2-2-计算所属类的概率" class="headerlink" title="2.2 计算所属类的概率"></a>2.2 计算所属类的概率</h2><p>上面计算的高斯分布是针对一个属性属于某一类的可能性，那么合并一个数据样本中所有属性的概率，最后便得到整个数据样本属于某个类的概率。<br>传入的是已知的均值标准差、测试样本，计算返回的是该样本属于每个类的可能性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateClassProbabilities</span><span class="params">(summaries, sample)</span>:</span></span><br><span class="line">    probabilities = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> summaries.items():</span><br><span class="line">        probabilities[key] = <span class="number">1</span>   <span class="comment">#初始化为1，便于进行之后的乘法</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(value)):   <span class="comment"># 每一个value代表的是一个列表，列表中的每一项是该属性的均值和方差</span></span><br><span class="line">            mean,stdev = value[i]</span><br><span class="line">            x = sample[i]</span><br><span class="line">            temp = calculateGauss(x,mean,stdev)</span><br><span class="line">            probabilities[key] *= temp</span><br><span class="line">    <span class="keyword">return</span> probabilities</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sample = [<span class="number">14.12</span>,<span class="number">1.48</span>,<span class="number">2.32</span>,<span class="number">16.8</span>,<span class="number">95</span>,<span class="number">2.2</span>,<span class="number">2.43</span>,<span class="number">.26</span>,<span class="number">1.57</span>,<span class="number">5</span>,<span class="number">1.17</span>,<span class="number">2.82</span>,<span class="number">1280</span>]</span><br><span class="line">calculateClassProbabilities(summaries,sample)</span><br></pre></td></tr></table></figure>
<pre><code>输出：{1.0: 4.447223997425311e-07,
 2.0: 4.484204868285748e-15,
 3.0: 9.048504947577875e-28}
</code></pre><h2 id="2-3-单一预测"><a href="#2-3-单一预测" class="headerlink" title="2.3 单一预测"></a>2.3 单一预测</h2><p>根据可能性大小，预测对应样本的所属类别</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(summaries, sample)</span>:</span></span><br><span class="line">    probabilities = calculateClassProbabilities(summaries,sample)</span><br><span class="line">    bestLabel = <span class="literal">None</span></span><br><span class="line">    bestProbability = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> probabilities.items():</span><br><span class="line">        <span class="keyword">if</span> bestLabel <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> value&gt;bestProbability:</span><br><span class="line">            bestLabel = key</span><br><span class="line">            bestProbability = value</span><br><span class="line">    <span class="keyword">return</span> bestLabel</span><br><span class="line"></span><br><span class="line">sample = [<span class="number">14.12</span>,<span class="number">1.48</span>,<span class="number">2.32</span>,<span class="number">16.8</span>,<span class="number">95</span>,<span class="number">2.2</span>,<span class="number">2.43</span>,<span class="number">.26</span>,<span class="number">1.57</span>,<span class="number">5</span>,<span class="number">1.17</span>,<span class="number">2.82</span>,<span class="number">1280</span>]</span><br><span class="line">label = predict(summaries,sample)</span><br><span class="line">print(label)</span><br></pre></td></tr></table></figure>
<pre><code>输出：1.0
</code></pre><h2 id="2-4-评估"><a href="#2-4-评估" class="headerlink" title="2.4 评估"></a>2.4 评估</h2><h3 id="2-4-1-多重预测"><a href="#2-4-1-多重预测" class="headerlink" title="2.4.1 多重预测"></a>2.4.1 多重预测</h3><p>预测测试数据集中每个数据样本的预测，返回测试样本的预测列表。参数：summaries表示的是属性的特征（均值，标准差）。testData表示的是测试数据集。返回的是关于每一个测试数据的预测label。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPredictions</span><span class="params">(summaries, testData)</span>:</span></span><br><span class="line">    predictions = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> testData:</span><br><span class="line">        temp = item[<span class="number">1</span>:]</span><br><span class="line">        label =  predict(summaries,temp)</span><br><span class="line">        predictions.append(label)</span><br><span class="line">    <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line">predictions = getPredictions(summaries,testData)</span><br></pre></td></tr></table></figure>
<h3 id="2-4-2-计算精度"><a href="#2-4-2-计算精度" class="headerlink" title="2.4.2 计算精度"></a>2.4.2 计算精度</h3><p>将预测值和测试数据集中的类别进行比较，计算得到一个介于0-1之间的精确率作为分类的精度。testData是测试集，predictions是预测的label值。返回预测准确的个数和精确率。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAccuracy</span><span class="params">(testData, predictions)</span>:</span></span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testData)):</span><br><span class="line">        <span class="keyword">if</span>(testData[i][<span class="number">0</span>] == predictions[i]):</span><br><span class="line">            count += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> (count, count/float(len(testData)))</span><br><span class="line"></span><br><span class="line">count,accuracy = getAccuracy(testData, predictions)</span><br><span class="line">print(<span class="string">"testData is %d lines, predict accuracy is %d lines, the accuracy is %.4f"</span> % (len(testData), count, accuracy))</span><br></pre></td></tr></table></figure>
<pre><code>输出：testData is 59 lines, predict accuracy is 57 lines, the accuracy is 0.9661
</code></pre><h1 id="3-合并代码"><a href="#3-合并代码" class="headerlink" title="3 合并代码"></a>3 合并代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">filename = <span class="string">r'C:\Users\14259\Desktop\23周\wine.csv'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将读取文件内容封装成方法，存到二维数组中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadCsvFile</span><span class="params">(filename)</span>:</span></span><br><span class="line">    csv_reader = csv.reader(open(filename,<span class="string">'r'</span>))</span><br><span class="line">    dataset = list(csv_reader)</span><br><span class="line"><span class="comment">#     print(dataset)</span></span><br><span class="line">    <span class="comment"># 将数据类型由字符串转换成浮点数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">        dataset[i] = [float(x) <span class="keyword">for</span> x <span class="keyword">in</span> dataset[i]]</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分数据集为训练数据和测试数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">splitDataset</span><span class="params">(dataset,splitRatio)</span>:</span></span><br><span class="line">    <span class="comment"># splitRation 是训练数据占得比例</span></span><br><span class="line">    data= copy.deepcopy(dataset)</span><br><span class="line">    length = len(dataset)</span><br><span class="line">    trainSize= math.floor(length*splitRatio)</span><br><span class="line">    trainData = []</span><br><span class="line">    <span class="keyword">while</span>(len(trainData)&lt;trainSize):</span><br><span class="line">        index = random.randint(<span class="number">0</span>,len(data)<span class="number">-1</span>)</span><br><span class="line">        trainData.append(data.pop(index))</span><br><span class="line">    testData = data</span><br><span class="line">    <span class="keyword">return</span> [trainData,testData]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将类别作为键，对应类别的值等作为改建对应的值</span></span><br><span class="line"><span class="comment"># 按照类别进行数据分类，返回一个对象，键为label值，值为属于该label的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">separateByClass</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    dataClass = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)):</span><br><span class="line">        item = dataset[i]  </span><br><span class="line">        <span class="keyword">if</span>(item[<span class="number">0</span>] <span class="keyword">not</span> <span class="keyword">in</span> dataClass.keys()):  <span class="comment"># 如果没有该键值</span></span><br><span class="line">            dataClass[item[<span class="number">0</span>]] = []</span><br><span class="line">        dataClass[item[<span class="number">0</span>]].append(item)</span><br><span class="line">    <span class="keyword">return</span> dataClass</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算均值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mean</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> sum(numbers) / float(len(numbers));</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算标准差</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">stdev</span><span class="params">(numbers)</span>:</span></span><br><span class="line">    avg = mean(numbers)</span><br><span class="line">    variance = sum([pow(x-avg,<span class="number">2</span>) <span class="keyword">for</span> x <span class="keyword">in</span> numbers])/(float(len(numbers)<span class="number">-1</span>))  <span class="comment"># 这里使用len(numbers)-1,可以参考百度百科【标准差】的说法</span></span><br><span class="line">    <span class="keyword">return</span> math.sqrt(variance)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取数据特征，返回的是dataset数据的均值和标准差列表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">summrize</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    summaries = [(mean(attributes),stdev(attributes)) <span class="keyword">for</span> attributes <span class="keyword">in</span> zip(*dataset)]</span><br><span class="line">    <span class="keyword">del</span> summaries[<span class="number">0</span>]   <span class="comment"># 第一列表示的是类别列，不需要，可以删除</span></span><br><span class="line">    <span class="keyword">return</span> summaries</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照类别提取属性特征</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">summrizeByClass</span><span class="params">(dataset)</span>:</span></span><br><span class="line">    seperateData = separateByClass(dataset)      <span class="comment"># 获取分类之后的数据</span></span><br><span class="line">    summaries = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> seperateData.items():</span><br><span class="line">        summaries[key] = summrize(value)</span><br><span class="line">    <span class="keyword">return</span> summaries</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算高斯函数值，也就是某属性x在该类别下的概率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateGauss</span><span class="params">(x,mean,stdev)</span>:</span></span><br><span class="line">    <span class="comment"># x表示对应的属性值，mean是该属性在某一类别下的均值，stdev是标准差</span></span><br><span class="line">    fenmu = math.exp(-math.pow((x-mean),<span class="number">2</span>)/(<span class="number">2</span>*math.pow(stdev,<span class="number">2</span>)))</span><br><span class="line">    fenzi = math.sqrt(<span class="number">2</span>*math.pi)*stdev</span><br><span class="line">    <span class="keyword">return</span> fenmu/fenzi</span><br><span class="line"></span><br><span class="line"><span class="comment">#  计算某一个数据多个属性属于label的可能性，返回的是一个对象，键值label，值是该数据属于该label的可能性</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculateClassProbabilities</span><span class="params">(summaries, sample)</span>:</span></span><br><span class="line">    probabilities = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> summaries.items():</span><br><span class="line">        probabilities[key] = <span class="number">1</span>   <span class="comment">#初始化为1，便于进行之后的乘法</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(value)):   <span class="comment"># 每一个value代表的是一个列表，列表中的每一项是该属性的均值和方差</span></span><br><span class="line">            mean,stdev = value[i]</span><br><span class="line">            x = sample[i]</span><br><span class="line">            temp = calculateGauss(x,mean,stdev)</span><br><span class="line">            probabilities[key] *= temp</span><br><span class="line">    <span class="keyword">return</span> probabilities</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测某一个样本的label</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(summaries, sample)</span>:</span></span><br><span class="line">    probabilities = calculateClassProbabilities(summaries,sample)</span><br><span class="line">    bestLabel = <span class="literal">None</span></span><br><span class="line">    bestProbability = <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> probabilities.items():</span><br><span class="line">        <span class="keyword">if</span> bestLabel <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> value&gt;bestProbability:</span><br><span class="line">            bestLabel = key</span><br><span class="line">            bestProbability = value</span><br><span class="line">    <span class="keyword">return</span> bestLabel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测测试数据的分类</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPredictions</span><span class="params">(summaries, testData)</span>:</span></span><br><span class="line">    predictions = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> testData:</span><br><span class="line">        temp = item[<span class="number">1</span>:]</span><br><span class="line">        label =  predict(summaries,temp)</span><br><span class="line">        predictions.append(label)</span><br><span class="line">    <span class="keyword">return</span> predictions</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAccuracy</span><span class="params">(testData, predictions)</span>:</span></span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testData)):</span><br><span class="line">        <span class="keyword">if</span>(testData[i][<span class="number">0</span>] == predictions[i]):</span><br><span class="line">            count += <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> (count, count/float(len(testData)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 加载数据集</span></span><br><span class="line">    dataset = loadCsvFile(filename)</span><br><span class="line">    print(<span class="string">"loaded data file &#123;0&#125; with &#123;1&#125; lines"</span>.format (filename,len(dataset)))</span><br><span class="line">    <span class="comment"># 切分数据</span></span><br><span class="line">    trainData,testData = splitDataset(dataset,<span class="number">0.67</span>)</span><br><span class="line">    print(<span class="string">"train data is %d lines and test data is %d lines"</span> % (len(trainData),len(testData)))</span><br><span class="line">    <span class="comment"># 获取数据特征</span></span><br><span class="line">    summaries = summrizeByClass(trainData)</span><br><span class="line">    <span class="comment"># 进行预测</span></span><br><span class="line">    predictions = getPredictions(summaries,testData)</span><br><span class="line">    <span class="comment"># 计算准确率</span></span><br><span class="line">    count,accuracy = getAccuracy(testData, predictions)</span><br><span class="line">    print(<span class="string">"testData is %d lines, predict accuracy is %d lines, the accuracy is %.4f"</span> % (len(testData), count, accuracy))</span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure>
<pre><code>输出：loaded data file C:\Users\14259\Desktop\23周\wine.csv with 178 lines
train data is 119 lines and test data is 59 lines
testData is 59 lines, predict accuracy is 56 lines, the accuracy is 0.9492
</code></pre><h1 id="4-扩展"><a href="#4-扩展" class="headerlink" title="4 扩展"></a>4 扩展</h1><h2 id="4-1-计算所属类的概率"><a href="#4-1-计算所属类的概率" class="headerlink" title="4.1 计算所属类的概率"></a>4.1 计算所属类的概率</h2><p>上面在进行分类的时候，只是单一的计算对应可能性大小，没有计算所属类的概率。计算所属类的概率，只需要用属于当前类的可能性比上总的可能性大小即可。参数probabilities是可能性的相对大小，在前文中使用calculateClassProbabilities()函数中可以计算得到。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getProbabilities</span><span class="params">(probabilities)</span>:</span></span><br><span class="line">    probs = &#123;&#125;</span><br><span class="line">    allProb = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> probabilities.items():</span><br><span class="line">        allProb += value</span><br><span class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> probabilities.items():</span><br><span class="line">        probs[key]  = <span class="string">'&#123;:.4f&#125;'</span>.format(value/allProb)</span><br><span class="line">    <span class="keyword">return</span> probs</span><br><span class="line"></span><br><span class="line">sample = [<span class="number">14.12</span>,<span class="number">1.48</span>,<span class="number">2.32</span>,<span class="number">16.8</span>,<span class="number">95</span>,<span class="number">2.2</span>,<span class="number">2.43</span>,<span class="number">.26</span>,<span class="number">1.57</span>,<span class="number">5</span>,<span class="number">1.17</span>,<span class="number">2.82</span>,<span class="number">1280</span>]</span><br><span class="line">probabilities = calculateClassProbabilities(summaries,sample)</span><br><span class="line">getProbabilities(probabilities)</span><br></pre></td></tr></table></figure>
<pre><code>输出：{1.0: &apos;1.0000&apos;, 2.0: &apos;0.0000&apos;, 3.0: &apos;0.0000&apos;}
</code></pre><h2 id="4-2-思路拓展"><a href="#4-2-思路拓展" class="headerlink" title="4.2 思路拓展"></a>4.2 思路拓展</h2><ul>
<li>对数概率。 对于一个给定的属性值，每个类的条件概率很小。当将它们相乘的时候结果会更小，那么存在浮点数溢出的可能性。一个常用的修复方案是合并其概率的对数值。（这个怎么合并）</li>
<li>不同密度函数。已经尝试了高斯朴素贝叶斯，可以尝试其他不同的分布。比如多项分布、伯努利分布或者内核朴素贝叶斯。</li>
</ul>
<p>参考链接<a href="http://python.jobbole.com/81019/?f=geek#article-comment" target="_blank" rel="noopener">这里</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/07/MachineLearningAndDataMining/朴素贝叶斯/" data-id="cjtinfpre0044xw77ynayih34" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/分类/">分类</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/贝叶斯/">贝叶斯</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-MachineLearningAndDataMining/数据挖掘理论与算法-数据预处理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/08/03/MachineLearningAndDataMining/数据挖掘理论与算法-数据预处理/" class="article-date">
  <time datetime="2018-08-03T06:47:29.000Z" itemprop="datePublished">2018-08-03</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/数据挖掘/">数据挖掘</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/03/MachineLearningAndDataMining/数据挖掘理论与算法-数据预处理/">数据挖掘理论与算法-数据预处理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>　　本周根据学堂在线的数据预处理课程的学习，根据课堂中的理论知识，查阅资料，使用SPSS软件进行相关的操作。课程截图如下：  </p>
<div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/1.png" width="200px;" height="300px">图1 数据预处理课程截图</div>

<p>在以上数据预处理的相关课程中，我主要使用SPSS分析软件进行了以下工作：</p>
<ul>
<li>异常值与重复数据检测、类型转换与采样</li>
<li>主成分分析法</li>
<li>线性判别分析<br>在学习相关的主成分分析法和线性判别分析课程之后，了解它们的工作原理。</li>
</ul>
<h1 id="2-数据来源"><a href="#2-数据来源" class="headerlink" title="2. 数据来源"></a>2. 数据来源</h1><p>　　从UCI Machine Learning Repository中下载的最流行的数据集wine，该数据集是用于分类测试的数据集，数据集描述信息如下表：</p>
<style>
table th:first-of-type {
    width: 80px;
}
table th:nth-of-type(2) {
    width: 80px;
}
</style>

<table>
<thead>
<tr>
<th>数据量</th>
<th>178（条）</th>
<th>&nbsp;</th>
</tr>
</thead>
<tbody>
<tr>
<td>属性数目</td>
<td>13（个）</td>
<td>1) Alcohol（乙醇）<br>2) Malic acid（苹果酸）<br>3) Ash（灰分）<br>4) Alkalinity of ash（灰分碱度）<br>5) Magnesium（镁）<br>6) Total phenols（总石碳酸）<br>7) Flavanoids（黄酮）<br>8) Nonflavanoid phenols（非黄酮类）<br>9) Proanthocyanins（花青素）<br>10)Color intensity（颜色强度）<br>11)Hue（色度）<br>12)OD280/OD315 of diluted wines（经稀释之后的吸光度比值）<br>13)Proline（脯氨酸）</td>
</tr>
<tr>
<td>类别</td>
<td>3（个）</td>
<td>对应每一类别的数量如下：<br>Class 1:59 <br> Class 2:71  <br>Class 3:48 <br> Total：178</td>
</tr>
</tbody>
</table>
<p>部分数据图2所示，其中13个属性的值都是连续的。</p>
<div align="center"><br>    <img src="/images/DataMiningTheory/DataPreprocessing/2.png"><br>    图2 部分数据截图<br></div>

<h1 id="3-数据分析"><a href="#3-数据分析" class="headerlink" title="3. 数据分析"></a>3. 数据分析</h1><h2 id="3-1-异常值与重复数据检测"><a href="#3-1-异常值与重复数据检测" class="headerlink" title="3.1 异常值与重复数据检测"></a>3.1 异常值与重复数据检测</h2><p>　　考虑到所下载的数据集是已经经过处理的数据，因此数据中不包含重复的数据，这里我人为的添加了5条重复数据，之后使用SPSS分析软件进行重复数据的检测。得到所有最后一个匹配个案的指示符为主个案，见下表:</p>
<table>
<thead>
<tr>
<th></th>
<th>频率</th>
<th>百分比</th>
<th>有效百分比</th>
<th>累积百分比</th>
</tr>
</thead>
<tbody>
<tr>
<td>重复个案</td>
<td>5</td>
<td>2.7</td>
<td>2.7</td>
<td>2.7</td>
</tr>
<tr>
<td>有效 主个案</td>
<td>178</td>
<td>97.3</td>
<td>97.3</td>
<td>100.0</td>
</tr>
<tr>
<td>合计</td>
<td>183</td>
<td>100.0</td>
<td>100.0</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
<p>　　关于异常值的检测课程，里面主要讲了一下离群点对数据的影响，通过查阅《数据挖掘概念与技术》这本书，识别可以的离群点的通常规则是，挑选落在第3个四分位数之上或者第一个四分位数之下至少1.5*IQR处的值，其中IQR是四分位数极差。使用SPSS对Alcohol属性进行离群点的检验，得到数据盒图如图3。</p>
<div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/3.png" width="400px;" height="400px">图 3 在不同type下Alcohol的盒图</div> 

<p>对盒图做一些说明：</p>
<ul>
<li>盒的端点一般在四分位数线上，盒的长度是四分位数的极差IQR；</li>
<li>中位数用盒内的线标记</li>
<li>盒外的两条线延伸到最小和最大的观测值。</li>
</ul>
<h2 id="3-2-主成分分析法"><a href="#3-2-主成分分析法" class="headerlink" title="3.2 主成分分析法"></a>3.2 主成分分析法</h2><p>　　主成分分析法（PCA）是一种通过降维来简化数据结构的方法，如果把多个变量化为少数几个综合变量，而这几个综合变量可以反映原来多个变量的大部分信息，所含的信息又互相不重叠，即他们之间要相互独立，互不相关。</p>
<p>　　主成分分析法的基本思想就是，找出P维空间中椭球体的主轴的问题，如图４所示，在二维空间中，数据的分布呈现出一个椭球体的样子，以椭圆的长轴和短轴作为新的坐标轴y1、y2，此时y1和y2已经不再相关（正交），而且大部分点沿y1散开。通过公式推导（公式推导部分没有自己看），可以得出最大变动方向是由特征向量决定，而特征值刻画对应的方差。</p>
<div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/4.png" width="400px;" height="400px">图 4 二维数据分布图</div> 


<p>　　使用SPSS分析软件进行主成分分析法，首先需要对数据进行标准化，之后设置特征根的临界值为0.8，迭代次数设置为50次，得到的解释方差图如图5所示。</p>
<div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/5.png" width="400px;" height="400px">图 5 主成分分析法–解释总方差</div> 


<p>　　其中“合计”一栏表示的是相关系数矩阵的各个特征值，因为设定的临界值为0.8，这里会得到对应的5个主成分。</p>
 <div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/6.png" width="400px;" height="400px">图 6 主成分分析法–成分矩阵</div> 

<p>　　在图6所示的成分矩阵中，图中的1-5的每一列中显示了每个属性与主成分的相关系数，这5个主成分其实是原先13个变量的线性组合。就第1列为例，主成分的值为Z=0.313*Zscore(Alcohol)-0.532*Zscore(MalicAcid)-0.004*Zscore(Ash)-0.519*Zscore(Megnesium)<br>+0.856*Zscore(TotalPhenols)+….。将这13个属性对应的第一列的值作为系数，系数越大，表示主成分对该变量的代表性越大。</p>
<h2 id="3-3-线性判别分析"><a href="#3-3-线性判别分析" class="headerlink" title="3.3 线性判别分析"></a>3.3 线性判别分析</h2><p>　　线性判别分析（LDA）是将高纬的模式样本投影到最佳鉴别的矢量空间，以达到抽取分类信息和压缩特征空间维数的效果。<br>　　如图7所示，数据总体上的分布是沿着图中红色剪头的方向，当使用PCA进行降维时，数据会投影到该红色箭头上方向，从而导致无法进行分类。因为PCA是不考虑label，是一种非监督的。</p>
 <div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/7.png" width="400px;" height="400px">图 7 分类数据点图</div> 

<p>　　针对以上现象，如果是有标签的数据，使用LDA分析，保留对应的分类信息。如图8所示。这两个坐标系中的数据是一样的，从不同的方向进行投影的时候，左边的投影中蓝颜色和红颜色点重叠在一起，无法进行分类。而右边很好的将蓝颜色和红颜色的点进行了区分，因此说明选择不同的投影方向是很重要的。</p>
 <div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/8.png" width="400px;" height="400px">图 8 不同投影坐标下的分类</div> 


<p>　　使用SPSS分析软件进行判别分析。下面只是截取了部分的图形呈现，从图9中可以看出整体的分类效果还是不错的，图10中是详细的分类结果，可以看出有一个是判断错误，本来类别是2，判定为3。整体准确率是99.4%。</p>
 <div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/9.png" width="400px;" height="400px">图 9 判别函数散点图</div> 

 <div align="center"><img src="/images/DataMiningTheory/DataPreprocessing/10.png" width="400px;" height="400px">图 10 分类结果</div> 


<h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h1><p>　　本周主要采用了SPSS分析工具，针对数据预处理中的一些步骤进行了分析。了解了主成分分析法和线性判别分析的原理，也是用SPSS分析软件对其进行了简单的分析，在一些值的设定上面是参考别人的，可能并不是很适合自己的数据，需要了解每一部分参数的含义。<br>　　整体上，本周初步完成了学堂在线课程的《数据预处理》部分的理论学习和实践，接下来需要完善的是了解每一部分参数的含义，从而更加熟练的使用SPSS分析软件。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/08/03/MachineLearningAndDataMining/数据挖掘理论与算法-数据预处理/" data-id="cjtinfpp5000pxw77a417jsg6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/SPSS/">SPSS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据分析/">数据分析</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-weibo/从零开始学习爬取微博数据" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/27/weibo/从零开始学习爬取微博数据/" class="article-date">
  <time datetime="2018-07-27T06:32:47.000Z" itemprop="datePublished">2018-07-27</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/weibo/">weibo</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/27/weibo/从零开始学习爬取微博数据/">从零开始学习爬取微博数据</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="1-微博高级检索工具"><a href="#1-微博高级检索工具" class="headerlink" title="1. 微博高级检索工具"></a>1. 微博高级检索工具</h1><p>首先，使用微博进行搜索，在搜索结果中可以看到下图中的结果。前提是需要已经登录了微博，如果没有登录，那么就不会有“高级搜索”的。</p>
<p><img src="/images/weibo/weibo_04.png" alt="高级搜索"></p>
<p>之后点击之后的具体界面如下图</p>
<p><img src="/images/weibo/weibo_03.png" alt="高级搜索"></p>
<p>这里主要说一下在对这些内容进行编码的时候遇到的问题。首先看一下高级检索工具得到的URL地址<br><a href="http://s.weibo.com/weibo/%25E9%25B9%25BF%25E6%2599%2597&amp;region=custom:42:1&amp;typeall=1&amp;suball=1&amp;timescope=custom:2018-07-26-11:2018-07-27-13&amp;Refer=g" target="_blank" rel="noopener">http://s.weibo.com/weibo/%25E9%25B9%25BF%25E6%2599%2597&amp;region=custom:42:1&amp;typeall=1&amp;suball=1&amp;timescope=custom:2018-07-26-11:2018-07-27-13&amp;Refer=g</a><br>将他们切分开然后进行对应的分析说明  </p>
<ul>
<li>%25E9%25B9%25BF%25E6%2599%2597   这一部分其实就是关键词“鹿晗”进行编码之后形成的</li>
<li>region=custom:42:1  这一部分是地点，应该有对应的编码表，我选择的是湖北 襄阳</li>
<li>typeall=1  这个就是“类型”，1表示全部，hot表示热门，对应的其他的可以及其了解一下</li>
<li>suuall=1  就是“包含”，1表示全部</li>
<li>timescope=custom:2018-07-26-11:2018-07-27-13  这里就是时间范围了，最小粒度是小时，这里就是从26号的11时到27号的13时。</li>
<li>&amp;Refer=g   这个就不是很清楚了。</li>
</ul>
<p>首先是关键词，微博对关键词的编码是进行了两次，如下，其中s_code1是通过高级搜索工具进行搜索的时候得到的关键字对应的编码，需要解码两次得到想要的结果。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line">s_code1 = <span class="string">"%25E9%25B9%25BF%25E6%2599%2597"</span></span><br><span class="line">s_code2 = urllib.parse.unquote(s_code1)</span><br><span class="line"><span class="comment"># 解码</span></span><br><span class="line">print(urllib.parse.unquote(s_code2))</span><br></pre></td></tr></table></figure></p>
<p>接着是关于高级检索的时间设置问题，当设置检索的时间为2018-07-26-11至2018-07-26-12，此时搜索出来的微博是从11:00–12:59之间的微博，这需要注意一下。因此如果想获取一个小时内的数据，应该设置的小时是一样的。</p>
<h1 id="2-微博爬虫"><a href="#2-微博爬虫" class="headerlink" title="2. 微博爬虫"></a>2. 微博爬虫</h1><p>其实写这一部分的时候微博爬虫的代码还没有写出来，主要说明一下目前遇到的一些问题，当这些问题解决了之后应该就容易了。<br>首先，微博的反爬虫机制是比较强大的，主要是关于微博账号和IP地址的问题。因为代理IP的价格问题等因素，这里主要是想准备采用多个微博账号轮流进行抓取，同时设置延迟。<br>使用多个微博账号，需要首先获取这些微博账号的Cookie，之后存储起来，然后轮流进行数据的获取，但是这样有一个问题就是，轮流抓取的话如何记录抓取的状态，目前还没有解决。  </p>
<h2 id="2-1-使用的python库"><a href="#2-1-使用的python库" class="headerlink" title="2.1 使用的python库"></a>2.1 使用的python库</h2><p>因为在进行微博网站分析的时候，在搜索结果的源代码中发现没有对应的想获取的信息，有些数据是通过动态加载的，通过JS或者Ajax代码进行加载的。通过分析网络请求发现，也不是通过Ajax加载的，在Ajax请求中，只有一个md5_mapping_file.json文件，不知道用处。因此只能等页面加载完成之后再获取数据，而正好有一个库文件Selenium可以解决这种情况。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup   <span class="comment"># 页面解析工具</span></span><br><span class="line"></span><br><span class="line">driver = webdriver.Firefox()    <span class="comment"># 加载火狐浏览器的驱动</span></span><br><span class="line">url = <span class="string">"http://s.weibo.com/weibo/%25E9%2595%25BF%25E6%2598%25A5%25E7%2596%25AB%25E8%258B%2597&amp;typeall=1&amp;suball=1&amp;timescope=custom:2018-07-15-11:2018-07-15-15&amp;Refer=g"</span></span><br><span class="line">driver.get(url,cookiess=Cookie)</span><br><span class="line">html = driver.page_source         <span class="comment"># 此时已经获取到加载之后的数据，接着开始使用BeautifulSoup进行数据的获取</span></span><br><span class="line">soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br></pre></td></tr></table></figure></p>
<p>其中selenium可以通过pip进行安装，而对应的浏览器的驱动可以在这里下载<a href="https://npm.taobao.org/mirrors/geckodriver/" target="_blank" rel="noopener">firefoxDriver</a>，需要注意的是和自己已经安装的浏览器的版本已经Selenium的版本适配。通过在命令行下使用pip freeze可以查看已经安装的selenium的版本。<br>【注意】我在使用chromeDriver的时候一直报错，可能就是版本问题，之后重新使用了firefoxDriver就好了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/27/weibo/从零开始学习爬取微博数据/" data-id="cjtinfpq0001pxw77p7pj4jx3" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/weibo/">weibo</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-weibo/获取微博数据中的总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/20/weibo/获取微博数据中的总结/" class="article-date">
  <time datetime="2018-07-20T12:05:51.000Z" itemprop="datePublished">2018-07-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/weibo/">weibo</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/20/weibo/获取微博数据中的总结/">获取微博数据中的总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>本文主要记录在这周在找获取微博数据的过程中遇到的一些问题，便于以后回顾。</p>
<h1 id="微博数据采集软件分析"><a href="#微博数据采集软件分析" class="headerlink" title="微博数据采集软件分析"></a>微博数据采集软件分析</h1><p>主要使用了八爪鱼采集器、集搜客（GooSeeker）</p>
<h2 id="八爪鱼采集器使用"><a href="#八爪鱼采集器使用" class="headerlink" title="八爪鱼采集器使用"></a>八爪鱼采集器使用</h2><p>　　这个采集器是比较完善的采集器，这个客户端里面含有很多已经定义好的规则，当然也可以自己制定适合自己的规则，通过学习一些简单的操作，即通过输入、鼠标拖动、点击等操作即可，不用编写代码。<br>　　优点：对于一些网站都可以进行采集，熟悉使用之后，可以避免自己写python爬虫代码。至于IP代理以及爬取限制等，也能很好的进行处理。<br>　　缺点：客户端适应性有问题，最大化显示的时候有bug。另一点就是，当我要采集微博的数据的时候，每次点击都会特别卡顿，有时候会直接卡成“程序无响应”，优化感觉还不是很好。</p>
<h2 id="集搜客使用"><a href="#集搜客使用" class="headerlink" title="集搜客使用"></a>集搜客使用</h2><p>这个平台也需要下载客户端，在使用的时候可以有一些具体的微博小工具，包括点赞数据采集，关键词搜索，微博博主主页，转发&amp;评论内容等小功能，我主要使用了微博的关键词搜索，通过下面的输入方式，可以输入关键词，微博发布的时间，也可以细分时间段1-24小时</p>
<p><img src="/images/weibo/weibo_01.png" alt="关键词检索"></p>
<p>之后进行采集，需要采集的数据内容是设定好的。<br><img src="/images/weibo/weibo_02.png" alt="采集结果"></p>
<h1 id="一些在线的平台"><a href="#一些在线的平台" class="headerlink" title="一些在线的平台"></a>一些在线的平台</h1><p><a href="http://zmatrix.cn/" target="_blank" rel="noopener">蜘了</a>,该平台致力于为客户提供数据抓取，采集服务，网站数据抓取，数据抓取软件等等，我在该平台上申请体验，但是直到现在也还没有得到回复，貌似一般。</p>
<p><a href="http://docs.shenjianshou.cn/search/index.html" target="_blank" rel="noopener">神箭手</a>，该平台有对应的API开发文档，可以直接进行调用，需要一定的编码能力。同时在<a href="https://www.shenjianshou.cn/index.php?r=market/square" target="_blank" rel="noopener">神箭云市场</a>中也有对应的已经写好的爬虫，可以支付一定的金额获取，当然也可以找专人定制服务。</p>
<p><a href="http://ef.zhiweidata.com/#!/index" target="_blank" rel="noopener">知微事见</a>，一个免费公开的事件分析平台，网站看起来挺不错，但是当我检索“九寨沟地震”的时候，在数据下载界面，可以看到数据只有2万多条，数据应该不全或者是热门微博等，但是没有进行说明。同时虽然提供了数据下载服务，但是也不是免费的。</p>
<p><a href="http://vis.pku.edu.cn/weibova/weiboevents/index.html" target="_blank" rel="noopener">WeiboEvents</a>，北京大学PKUVIS微博可视化分析工具，具体怎么使用，目前还没有仔细看，但是貌似功能挺强大的。</p>
<p><a href="http://www.idataapi.cn/product/detail/160" target="_blank" rel="noopener">IDataAPI</a>，其实就是一个API的云市场，里面有一个关于微博，知乎等等网站的封装好的API接口，可以调用并进行访问。根据次数收费，微博API接口每100次1元，价格应该还好，得到的数据是JSON格式的，同时数据也比较详细。我测试了一下，同样搜索“九寨沟地震”，得到的数据貌似只有30多页，每一页20条左右，数据不完整。这里也可以提需求，之后会有人员联系你，然后再详细了解需求，看是否添加到云市场中。</p>
<p>当然还有爬山虎采集器，百度指数，新浪微指数等等平台。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>还有一个是微博自带的搜索功能————微博高级搜索，如下：</p>
<p><img src="/images/weibo/weibo_03.png" alt="微博高级搜索"></p>
<p>可以采集到的数据最多只有50页，每一页20条数据。这是微博的一个限制。一开始为了获取关于某一事件的全部数据还纠结了好久，现在发现貌似不能获取全部的数据，一种替代的想法就是获取热门微博。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/20/weibo/获取微博数据中的总结/" data-id="cjtinfpr60040xw77fedxy16x" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/工具/">工具</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/微博/">微博</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-others/c语言中关于串的相关知识以及操作" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/19/others/c语言中关于串的相关知识以及操作/" class="article-date">
  <time datetime="2018-07-19T11:43:02.000Z" itemprop="datePublished">2018-07-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/C语言/">C语言</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/19/others/c语言中关于串的相关知识以及操作/">c语言中关于串的相关知识以及操作</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="1-串的基本概念"><a href="#1-串的基本概念" class="headerlink" title="1 串的基本概念"></a>1 串的基本概念</h3><p> 串，即是字符串，由零个或者多个字符组成的有限序列，是数据元素为单个字符的特殊线性表。一般记为：S1=’a1a2a3a4a5….an’。</p>
<h3 id="2-串的存储结构："><a href="#2-串的存储结构：" class="headerlink" title="2 串的存储结构："></a>2 串的存储结构：</h3><p>   定长顺序存储结构、堆分配存储结构和块链存储结构三种。</p>
<h4 id="a-定长顺序存储结构"><a href="#a-定长顺序存储结构" class="headerlink" title="a.定长顺序存储结构"></a>a.<em>定长顺序存储结构</em></h4><p>定长顺序存储结构是用一组地址连续的存储单元存储串值的字符序列，就是将串定义成字符串数组。数组的名字就是串名。数组的上界预先给出，所以也称为静态存储。</p>
<p>存储结构定义如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 256</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> SString[MAXL+<span class="number">1</span>];<span class="comment">//0号单元用于存储串长，串值从1号单元开始放。</span></span><br><span class="line">另一种是从<span class="number">0</span>号单元开始存储串值。结构定义如下：</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 60</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span>&#123;</span></span><br><span class="line">    <span class="keyword">char</span> str[MAXL];</span><br><span class="line">    <span class="keyword">int</span> length;</span><br><span class="line">&#125;SString;</span><br></pre></td></tr></table></figure></p>
<p>此种存储结构有来两个缺点：<br>一是需要预先定义一个串允许的最大长度，当MAXL估计过大的时候串的存储密度就会降低，会浪费较多空间；二是由于限定了串的最大长度，使串的某些运算，比如联接收到一定限制。</p>
<h4 id="b-堆分配存储结构存储"><a href="#b-堆分配存储结构存储" class="headerlink" title="b.堆分配存储结构存储"></a>b.<em>堆分配存储结构存储</em></h4><p>它其实也是利用一组地址连续的存储单元存储串值的字符序列，但是存储空间是在程序运行的时候动态分配的。因此可以利用c语言中动态分配函数库中的malloc()来分配空间，还可以利用realloc()增加空间</p>
<p>存储结构定义如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">char</span> *ch;</span><br><span class="line">    <span class="keyword">int</span> length;</span><br><span class="line">&#125;HString;</span><br></pre></td></tr></table></figure></p>
<h4 id="c-块链存储结构"><a href="#c-块链存储结构" class="headerlink" title="c.块链存储结构"></a>c.<em>块链存储结构</em></h4><p>是使用链式存数结构存储串，每个节点有data域和next指针域组成。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> CHUNKSIZE 80</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">Chunk</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">char</span> ch[CHUNKSIZE];</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">CHunk</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;Chunk;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    Chunk *head,*tail;</span><br><span class="line">    <span class="keyword">int</span> curlen;</span><br><span class="line">&#125;LString;</span><br></pre></td></tr></table></figure>
<h3 id="串的相关操作："><a href="#串的相关操作：" class="headerlink" title="串的相关操作："></a>串的相关操作：</h3><h4 id="1-串赋值算法："><a href="#1-串赋值算法：" class="headerlink" title="1.串赋值算法："></a>1.串赋值算法：</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 256</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> str[MAXL];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">strAssign</span><span class="params">(str &amp;T, <span class="keyword">char</span> *chars)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    T[<span class="number">0</span>] = <span class="number">0</span>;<span class="comment">//0号单元存储字串长度</span></span><br><span class="line">    <span class="keyword">for</span> ( i = <span class="number">0</span>; chars[i]; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        T[i + <span class="number">1</span>] = chars[i];<span class="comment">//用字符数组chars给串赋值.</span></span><br><span class="line">    &#125;</span><br><span class="line">    T[<span class="number">0</span>] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    str T;</span><br><span class="line">    <span class="keyword">char</span> chars[] = <span class="string">"abcdefghijk"</span>;</span><br><span class="line">    strAssign(T, chars);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"串长是%d\n "</span>, T[<span class="number">0</span>]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"赋值后的串是 ："</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= T[<span class="number">0</span>]; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%c"</span>, T[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2-求子串算法："><a href="#2-求子串算法：" class="headerlink" title="2.求子串算法："></a>2.求子串算法：</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 256</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ERROR 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OK 1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> Status;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> str[MAXL];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">strAssign</span><span class="params">(str &amp;T, <span class="keyword">char</span> *s)</span></span></span><br><span class="line"><span class="function"><span class="comment">//用字符数组给T赋值</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    T[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; s[i]; i++) T[i + <span class="number">1</span>] = s[i];</span><br><span class="line">    T[<span class="number">0</span>] = i;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">subString</span><span class="params">(str &amp;sub, str T, <span class="keyword">int</span> pos, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"><span class="comment">//用sub返回第 pos个字符起长度为len的子串。</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (pos&lt;<span class="number">1</span> || pos&gt;T[<span class="number">0</span>] || len&lt;<span class="number">0</span> || len&gt;T[<span class="number">0</span>] - pos + <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> ERROR;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        sub[i] = T[pos + i - <span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    sub[<span class="number">0</span>] = len;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> pos, len;</span><br><span class="line">    str T, sub;</span><br><span class="line">    <span class="keyword">char</span> chars[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入字符串 "</span>);</span><br><span class="line">    <span class="comment">//scanf_s("%[^\n]", chars, sizeof(chars));//[^\n]只有遇到回车才会停止读入.</span></span><br><span class="line">    gets_s(chars);<span class="comment">//此处若是使用scanf_s()如上面注释的那样，也是没问题的.</span></span><br><span class="line">    strAssign(T, chars);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入子串开始的位置和长度（中间用逗号隔开） "</span>);</span><br><span class="line">    scanf_s(<span class="string">"%d,%d"</span>, &amp;pos, &amp;len);</span><br><span class="line">    getchar();</span><br><span class="line">    <span class="keyword">if</span> (subString(sub, T, pos, len))<span class="comment">//判断是否取子串成功.</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"从第%d位置开始，长度为%d的子串为 "</span>, pos, len);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= sub[<span class="number">0</span>]; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%c"</span>, sub[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"求子串失败.....\n"</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-串比较算法"><a href="#3-串比较算法" class="headerlink" title="3.串比较算法:"></a>3.串比较算法:</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OK 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ERROR 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OVERFLOW -1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> Status;</span><br><span class="line"><span class="comment">//串的堆分配存储表示</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	<span class="keyword">char</span> *ch;</span><br><span class="line">	<span class="keyword">int</span> length;</span><br><span class="line">&#125;HString;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">strAssign</span><span class="params">(HString &amp;s, <span class="keyword">char</span> *chars)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">char</span> *c = chars;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; *c; i++, c++);<span class="comment">//求chars的长度</span></span><br><span class="line">    <span class="keyword">if</span> (!i)</span><br><span class="line">    &#123;</span><br><span class="line">        s.ch = <span class="literal">NULL</span>;</span><br><span class="line">        s.length = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        s.ch = (<span class="keyword">char</span>*)<span class="built_in">malloc</span>(i*<span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line">        <span class="keyword">if</span> (!(s.ch))<span class="built_in">exit</span>(OVERFLOW);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            s.ch[j] = chars[j];</span><br><span class="line">        &#125;</span><br><span class="line">        s.length = i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> OK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Status <span class="title">strCompareTo</span><span class="params">(HString a, HString b)</span></span></span><br><span class="line"><span class="function"><span class="comment">//若a&lt;b,则则返回值&lt;0,若a&gt;b，则返回值&gt;0,若a=b,则返回值=0；</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; a.length&amp;&amp;b.length; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (a.ch[i] != b.ch[i])</span><br><span class="line">            <span class="keyword">return</span> (a.ch[i] - b.ch[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (a.length - b.length);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    HString Sa, Sb;</span><br><span class="line">    <span class="keyword">char</span> char_a[<span class="number">100</span>], char_b[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入字符串a:"</span>);</span><br><span class="line">    gets_s(char_a);</span><br><span class="line">    strAssign(Sa, char_a);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入字符串b:"</span>);</span><br><span class="line">    gets_s(char_b);</span><br><span class="line">    strAssign(Sb, char_b);</span><br><span class="line">    <span class="keyword">if</span> (strCompareTo(Sa, Sb) == <span class="number">0</span>)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"串 %s 等于串 %s"</span>, char_a, char_b);<span class="comment">//此处是char_a,char_b,不能是Sa，Sb.</span></span><br><span class="line">    <span class="keyword">if</span> (strCompareTo(Sa, Sb) &lt; <span class="number">0</span>)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"串 %s 小于串 %s"</span>, char_a,char_b);</span><br><span class="line">    <span class="keyword">if</span> (strCompareTo(Sa, Sb)&gt;<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"串 %s 等于串 %s"</span>, char_a, char_b);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="4-串联接算法"><a href="#4-串联接算法" class="headerlink" title="4.串联接算法"></a>4.串联接算法</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> TRUE 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> FALSE 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 255</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">int</span> Status;</span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> SString[MAXL + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">strAssign</span><span class="params">(SString &amp;T, <span class="keyword">char</span> *s)</span></span></span><br><span class="line"><span class="function"><span class="comment">//用字符数组s给串T赋值</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    T[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; s[i]; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        T[i + <span class="number">1</span>] = s[i];</span><br><span class="line">    &#125;</span><br><span class="line">    T[<span class="number">0</span>] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//定义了一个int型变量uncut，用于判断是否会被截断。</span></span><br><span class="line"><span class="comment">//uncun = TRUE时未被截断，uncut=FALSE时被截断。</span></span><br><span class="line"><span class="function">Status <span class="title">connect</span><span class="params">(SString &amp;T, SString S1, SString S2)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> uncut, i;</span><br><span class="line">    <span class="keyword">if</span> (S1[<span class="number">0</span>] + S2[<span class="number">0</span>] &lt;= MAXL)<span class="comment">//未截断，注意0号单元存储的是串长.</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= S1[<span class="number">0</span>]; i++)</span><br><span class="line">        T[i] = S1[i];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; S2[<span class="number">0</span>]; i++)</span><br><span class="line">        T[S1[<span class="number">0</span>] + i] = S2[i];</span><br><span class="line">    T[<span class="number">0</span>] = S1[<span class="number">0</span>] + S2[<span class="number">0</span>];</span><br><span class="line">    uncut = TRUE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (S1[<span class="number">0</span>] &lt; MAXL)<span class="comment">//S2被截断</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= S1[<span class="number">0</span>]; i++)</span><br><span class="line">        T[i] = S1[i];</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= MAXL - S1[<span class="number">0</span>]; i++)<span class="comment">//注意此时的循环条件.</span></span><br><span class="line">        T[S1[<span class="number">0</span>] + i] = S2[i];</span><br><span class="line">    T[<span class="number">0</span>] = MAXL;</span><br><span class="line">    uncut = FALSE;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span><span class="comment">//S1,S2均被截断。</span></span><br><span class="line">    &#123;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= MAXL; i++)</span><br><span class="line">        T[i] = S1[i];</span><br><span class="line">    uncut = FALSE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> uncut;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    SString S1, S2, T;</span><br><span class="line">    <span class="keyword">char</span> char_s1[<span class="number">100</span>], char_s2[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入字符串S1:"</span>);</span><br><span class="line">    gets_s(char_s1);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入字符串S2:"</span>);</span><br><span class="line">    gets_s(char_s2);</span><br><span class="line"></span><br><span class="line">    strAssign(S1, char_s1);</span><br><span class="line">    strAssign(S2, char_s2);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (connect(T, S1, S2))</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"S1= %s 和 S2= %s 联接过程中未被截断，连接后的串是: "</span>, char_s1, char_s2);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= T[<span class="number">0</span>]; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%c"</span>, T[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"S1= %s 和 S2= %s 联接过程中被截断，连接后的串是: "</span>, char_s1, char_s2);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= T[<span class="number">0</span>]; i++)</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%c"</span>, T[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="5-串的模式匹配算法"><a href="#5-串的模式匹配算法" class="headerlink" title="5.串的模式匹配算法"></a>5.串的模式匹配算法</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MAXL 255</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OK 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OVERFLOW -1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> SString[MAXL+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">strAssign</span><span class="params">(SString &amp;T, <span class="keyword">char</span> *s)</span></span></span><br><span class="line"><span class="function"><span class="comment">//用字符数组s给串T赋值.</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    T[<span class="number">0</span>] = <span class="number">0</span>;<span class="comment">//0号单元存储串长.</span></span><br><span class="line">    <span class="keyword">for</span> (; s[i]; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        T[i + <span class="number">1</span>] = s[i];</span><br><span class="line">    &#125;</span><br><span class="line">    T[<span class="number">0</span>] = i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">index</span><span class="params">(SString T, SString S, <span class="keyword">int</span> pos)</span></span></span><br><span class="line"><span class="function"><span class="comment">//返回子串S在主串T第pos个字符开始匹配的位置，若不存在，则返回0;</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = pos,j=<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt;= T[<span class="number">0</span>] &amp;&amp; j &lt;= S[<span class="number">0</span>])</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (T[i] == S[j])</span><br><span class="line">        &#123;</span><br><span class="line">            i++;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            i = i - j + <span class="number">2</span>;</span><br><span class="line">            j = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (j &gt; S[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> i - S[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> pos;</span><br><span class="line">    SString T, S;</span><br><span class="line">    <span class="keyword">char</span> char_a[<span class="number">100</span>], char_b[<span class="number">100</span>];</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入主串A："</span>);</span><br><span class="line">    gets_s(char_a);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, char_a);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"请输入主串B："</span>);</span><br><span class="line">    gets_s(char_b);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%s\n"</span>, char_b);</span><br><span class="line"></span><br><span class="line">    strAssign(T, char_a);</span><br><span class="line">    strAssign(S, char_b);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"赋值成功！\n"</span>);</span><br><span class="line"></span><br><span class="line">    pos = index(T, S, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (pos)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"主串 T=%s 的子串 S=%s 在第%d个位置开始匹配。"</span>,char_a,char_b,pos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"主串 T=%s 和子串 S=%s 不匹配"</span>,char_a,char_b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>   以上就是串相关知识以及一些简单操作，代码处理平台是vs2013。初来乍到，多多关照，有什么写的不对的，欢迎指正。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/19/others/c语言中关于串的相关知识以及操作/" data-id="cjtinfprf0046xw778xgdoml6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/C语言/">C语言</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/字符串/">字符串</a></li></ul>

    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/3/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Algorithm/">Algorithm</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C语言/">C语言</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/MachineLearning/">MachineLearning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python3/">python3</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/weibo/">weibo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/word2vec/">word2vec</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/数据挖掘/">数据挖掘</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Algorithm/">Algorithm</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/BP算法/">BP算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bayes/">Bayes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/C语言/">C语言</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DL/">DL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/EM/">EM</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/IO/">IO</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/KNN/">KNN</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MachineLearning/">MachineLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NLP/">NLP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SPSS/">SPSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/beautifulsoup/">beautifulsoup</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/collections/">collections</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/divide-and-conquer/">divide-and-conquer</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/file/">file</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/jieba/">jieba</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k-means/">k-means</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/kaggle/">kaggle</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/matplotlib/">matplotlib</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/">mysql</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/numpy/">numpy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pandas/">pandas</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-爬虫/">python 爬虫</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python3/">python3</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/realize/">realize</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/requests/">requests</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sklearn/">sklearn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/snippets/">snippets</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/weibo/">weibo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wiebo/">wiebo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/word2vec/">word2vec</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/全概率公式/">全概率公式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/决策树/">决策树</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/分类/">分类</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/动态规划/">动态规划</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/字符串/">字符串</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/小demo/">小demo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/工具/">工具</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/微博/">微博</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/支持向量机/">支持向量机</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/数据分析/">数据分析</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/时间复杂度/">时间复杂度</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/最大似然估计/">最大似然估计</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/算法/">算法</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/贝叶斯/">贝叶斯</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Algorithm/" style="font-size: 17.5px;">Algorithm</a> <a href="/tags/BP算法/" style="font-size: 10px;">BP算法</a> <a href="/tags/Bayes/" style="font-size: 10px;">Bayes</a> <a href="/tags/C语言/" style="font-size: 10px;">C语言</a> <a href="/tags/DL/" style="font-size: 10px;">DL</a> <a href="/tags/EM/" style="font-size: 10px;">EM</a> <a href="/tags/IO/" style="font-size: 10px;">IO</a> <a href="/tags/KNN/" style="font-size: 10px;">KNN</a> <a href="/tags/MachineLearning/" style="font-size: 12.5px;">MachineLearning</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/SPSS/" style="font-size: 10px;">SPSS</a> <a href="/tags/beautifulsoup/" style="font-size: 10px;">beautifulsoup</a> <a href="/tags/collections/" style="font-size: 10px;">collections</a> <a href="/tags/divide-and-conquer/" style="font-size: 10px;">divide-and-conquer</a> <a href="/tags/file/" style="font-size: 10px;">file</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/jieba/" style="font-size: 10px;">jieba</a> <a href="/tags/k-means/" style="font-size: 10px;">k-means</a> <a href="/tags/kaggle/" style="font-size: 10px;">kaggle</a> <a href="/tags/matplotlib/" style="font-size: 12.5px;">matplotlib</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/numpy/" style="font-size: 10px;">numpy</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/python-爬虫/" style="font-size: 10px;">python 爬虫</a> <a href="/tags/python3/" style="font-size: 10px;">python3</a> <a href="/tags/realize/" style="font-size: 10px;">realize</a> <a href="/tags/requests/" style="font-size: 10px;">requests</a> <a href="/tags/sklearn/" style="font-size: 10px;">sklearn</a> <a href="/tags/snippets/" style="font-size: 10px;">snippets</a> <a href="/tags/weibo/" style="font-size: 10px;">weibo</a> <a href="/tags/wiebo/" style="font-size: 10px;">wiebo</a> <a href="/tags/word2vec/" style="font-size: 10px;">word2vec</a> <a href="/tags/全概率公式/" style="font-size: 10px;">全概率公式</a> <a href="/tags/决策树/" style="font-size: 10px;">决策树</a> <a href="/tags/分类/" style="font-size: 12.5px;">分类</a> <a href="/tags/动态规划/" style="font-size: 10px;">动态规划</a> <a href="/tags/字符串/" style="font-size: 10px;">字符串</a> <a href="/tags/小demo/" style="font-size: 10px;">小demo</a> <a href="/tags/工具/" style="font-size: 10px;">工具</a> <a href="/tags/微博/" style="font-size: 10px;">微博</a> <a href="/tags/支持向量机/" style="font-size: 10px;">支持向量机</a> <a href="/tags/数据分析/" style="font-size: 10px;">数据分析</a> <a href="/tags/时间复杂度/" style="font-size: 10px;">时间复杂度</a> <a href="/tags/最大似然估计/" style="font-size: 10px;">最大似然估计</a> <a href="/tags/算法/" style="font-size: 12.5px;">算法</a> <a href="/tags/贝叶斯/" style="font-size: 10px;">贝叶斯</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">September 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/08/">August 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">July 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/03/21/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/11/02/Algorithms/DivideAndConquer/">Divide and Conquer</a>
          </li>
        
          <li>
            <a href="/2018/11/02/Algorithms/Dynamic-Planning/">Dynamic Planning</a>
          </li>
        
          <li>
            <a href="/2018/10/31/python3/word2vec/">word2vec</a>
          </li>
        
          <li>
            <a href="/2018/10/21/Algorithms/算法/">算法</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>